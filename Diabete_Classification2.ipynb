{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUjLEXZKsAbOkIIuxEgkZr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wanyoike274/Mxnet-Projects/blob/main/Diabete_Classification2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "SWC_RdxifnRk",
        "outputId": "2b60cca0-f477-4fbe-d643-f196e0c20f8f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-655e6558c412>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m                                       batch_size=batch_size, shuffle=True)\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Split the dataset into 80% training and 20% validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Define the loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'random_split'"
          ]
        }
      ],
      "source": [
        "import mxnet as mx\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "url = \"http://aka.ms/diabetes-data\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# Separate features and labels\n",
        "features = data.iloc[:, :-1].values\n",
        "labels = data.iloc[:, -1].values\n",
        "\n",
        "# Convert labels to numerical values\n",
        "label_map = {label: i for i, label in enumerate(set(labels))}\n",
        "labels = [label_map[label] for label in labels]\n",
        "\n",
        "# Define the network architecture\n",
        "net = mx.gluon.nn.Sequential()\n",
        "with net.name_scope():\n",
        "    net.add(mx.gluon.nn.Dense(64, activation='relu'))\n",
        "    net.add(mx.gluon.nn.Dense(32, activation='relu'))\n",
        "    net.add(mx.gluon.nn.Dense(2))\n",
        "\n",
        "# Initialize the network parameters\n",
        "net.initialize(mx.init.Xavier(magnitude=2.24))\n",
        "\n",
        "# Set the context to GPU if available, otherwise use CPU\n",
        "ctx = mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()\n",
        "\n",
        "# Create data iterators for training and validation\n",
        "batch_size = 32\n",
        "train_data = mx.gluon.data.DataLoader(mx.gluon.data.ArrayDataset(features, labels),\n",
        "                                      batch_size=batch_size, shuffle=True)\n",
        "# Split the dataset into 80% training and 20% validation\n",
        "train_data, val_data = train_data.random_split(0.8)\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = mx.gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = mx.gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': 0.001})\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0\n",
        "    for data, label in train_data:\n",
        "        data = data.as_in_context(ctx)\n",
        "        label = label.as_in_context(ctx)\n",
        "        with mx.autograd.record():\n",
        "            output = net(data)\n",
        "            loss = loss_fn(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step(data.shape[0])\n",
        "        train_loss += loss.mean().asscalar()\n",
        "    \n",
        "    # Calculate validation accuracy\n",
        "    val_accuracy = mx.metric.Accuracy()\n",
        "    for data, label in val_data:\n",
        "        data = data.as_in_context(ctx)\n",
        "        label = label.as_in_context(ctx)\n",
        "        output = net(data)\n",
        "        predictions = mx.nd.argmax(output, axis=1)\n",
        "        val_accuracy.update(label, predictions)\n",
        "    \n",
        "    print(f'Epoch {epoch+1}: Train Loss {train_loss/len(train_data)}, Val Accuracy {val_accuracy.get()[1]}')\n",
        "\n",
        "# Save the trained model\n",
        "net.save_parameters('model.params')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mxnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdQ57SN4f4LW",
        "outputId": "fb9e7a8b-d739-4530-ec19-1454c9dd9ab1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mxnet\n",
            "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (1.22.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (2.27.1)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet)\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.4)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.1\n",
            "    Uninstalling graphviz-0.20.1:\n",
            "      Successfully uninstalled graphviz-0.20.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bYfhOS-Hf-Wg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}